"""
A module to generate simulated 2D time-series SOSS data

Authors: Joe Filippazzo, Kevin Volk, Jonathan Fraine, Michael Wolfe
"""

import os
import sys
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import batman
import astropy.units as q
import astropy.constants as ac
import multiprocessing
import time
import AWESim_SOSS
import inspect
import warnings
import datetime
import webbpsf
import pkg_resources
from . import generate_darks as gd
from ExoCTK import core
from ExoCTK.ldc import ldcfit as lf
from astropy.io import fits
from scipy.optimize import curve_fit
from scipy.ndimage.interpolation import zoom
from scipy.interpolate import interp1d, _fitpack
from functools import partial
from sklearn.externals import joblib
from numpy.core.multiarray import interp as compiled_interp
from skimage.transform import PiecewiseAffineTransform, warp, estimate_transform

warnings.simplefilter('ignore')

cm = plt.cm
FRAME_TIMES = {'SUBSTRIP96':2.213, 'SUBSTRIP256':5.491, 'FULL':10.737}
SUBARRAY_Y = {'SUBSTRIP96':96, 'SUBSTRIP256':256, 'FULL':2048}

def make_linear_SOSS_trace(psfs, subarray='SUBSTRIP256', plot=False):
    """
    Construct the trace from the 2D psf generated by webbpsf at each wavelength
    
    Parameters
    ----------
    psfs: np.ndarray
        The data cube of shape (n_wavelengths, n_frames, x, y)
    subarray: str
        The subarray to use
    plot: bool
        Plot the trace
    
    Returns
    -------
    np.ndarray
        The 3D linear trace
    """
    # Get dimensions
    n_frames, n_waves, x, y = psfs.shape
    
    # Get the psf center
    c = int(x/2)
    
    # Get the subarray height
    Y = SUBARRAY_Y.get(subarray)
    
    # Empty trace (with padding for overflow)
    linear_trace = np.zeros((n_frames, n_waves+x, Y+y))
    
    # For each frame in the exposure...
    for N,frame in enumerate(psfs):
        
        # ... place psf in each column (i.e. wavelength)
        for n,wave in enumerate(frame):
            
            # Place the trace center in the correct column
            linear_trace[N,n:n+x,:y] += wave
            
    # Trim off padding
    linear_trace = linear_trace[:,c:-c,c:-c]
   
    # Transpose to DMS orientation
    linear_trace = linear_trace.swapaxes(1,2)
   
    # Plot it
    if plot:
        plt.figure(figsize=(13,2))
        plt.imshow(linear_trace[0], origin='lower', norm=matplotlib.colors.LogNorm())
        plt.xlim(0,2048)
        plt.ylim(0,Y)
        
    return linear_trace
    
def transform_from_polynomial(rows, cols, coeffs, downsample_rows=20, downsample_cols=50, plot=False):
    """
    Calculate the transform needed to warp one image into another
    
    Parameters
    ----------
    rows: int
        The number of rows
    cols: int
        The number of cols
    coeffs: sequence
        The list of polynomial coefficients (highest order first)
    downsample_rows: int
        The number of control points in the row direction
    downsample_cols: int
        The number of control points in the col direction
    plot: bool
        Plot for visual inspection
    
    Returns
    -------
    transform object
        The transform between the two sets of points
    """
    # Generate the control points
    src_cols = np.linspace(0, cols, cols//downsample_cols)
    src_rows = np.linspace(0, rows, rows//downsample_rows)
    src_rows, src_cols = np.meshgrid(src_rows, src_cols)
    src = np.dstack([src_cols.flat, src_rows.flat])[0]
    
    # Calculate the bottom of the curved trace
    # x_vals = np.arange(cols)
    # y_min = np.nanmin(np.polyval(coeffs, x_vals))
    
    # Add curvature to control points
    dst_cols = src[:,0]
    dst_rows = src[:,1]+np.polyval(coeffs, dst_cols)#-y_min
    dst = np.vstack([dst_cols, dst_rows]).T
    
    if plot:
        plt.figure(figsize=(13,2))
        plt.scatter(src_cols, src_rows, c='b', label='src')
        plt.scatter(dst_cols, dst_rows, c='r', label='dst')
        plt.xlim(0,cols)
        plt.ylim(0,rows)
        plt.legend(loc=0)
        
    # Perform transform
    tform = PiecewiseAffineTransform()
    tform.estimate(src, dst)
        
    return tform

def ADUtoFlux(order):
    """
    Return the wavelength dependent conversion from ADUs to erg s-1 cm-2 
    in SOSS traces 1, 2, and 3
    
    Parameters
    ----------
    order: int
        The trace order, must be 1, 2, or 3
    
    Returns
    -------
    np.ndarray
        Arrays to convert the given order trace from ADUs to units of flux
    """
    ADU2mJy, mJy2erg = 7.586031e-05, 2.680489e-15
    scaling = np.genfromtxt(pkg_resources.resource_filename('AWESim_SOSS', 'files/GR700XD_{}.txt'.format(order)), unpack=True)
    scaling[1] *= ADU2mJy*mJy2erg
    
    return scaling


def ldc_lookup(ld_profile, grid_point, delta_w=0.005, nrows=256, save=''):
    """
    Generate a lookup table of limb darkening coefficients for full SOSS wavelength range
    
    Parameters
    ----------
    ld_profile: str
        A limb darkening profile name supported by `ExoCTK.ldc.ldcfit.ld_profile()`
    grid_point: dict, sequence
        The stellar parameters [Teff, logg, FeH] or stellar model dictionary from `ExoCTK.core.ModelGrid.get()`
    delta_w: float
        The width of the wavelength bins in microns
    save: str
        The path to save to file to
    
    Example
    -------
    from AWESim_SOSS.sim2D import awesim
    lookup = awesim.ldc_lookup('quadratic', [3300, 4.5, 0])
    """
    print("Go get a coffee! This takes about 5 minutes to run.")
    
    # Initialize the lookup table
    lookup = {}
    
    # Get the full wavelength range
    wave_maps = wave_solutions(nrows)
    
    # Get the grid point
    if isinstance(grid_point, (list,tuple,np.ndarray)):
        
        grid_point = core.ModelGrid(os.environ['MODELGRID_DIR'], resolution=700, wave_rng=(0.6,2.6)).get(*grid_point)
        
    # Abort if no stellar dict
    if not isinstance(grid_point, dict):
        print('Please provide the grid_point argument as [Teff, logg, FeH] or ExoCTK.core.ModelGrid.get(Teff, logg, FeH).')
        return
        
    # Define function for multiprocessing
    def gr700xd_ldc(wavelength, delta_w, ld_profile, grid_point, model_grid):
        """
        Calculate the LCDs for the given wavelength range in the GR700XD grism
        """
        try:
            # Get the bandpass in that wavelength range
            mn = (wavelength-delta_w/2.)*q.um
            mx = (wavelength+delta_w/2.)*q.um
            throughput = np.genfromtxt(pkg_resources.resource_filename('AWESim_SOSS', 'files/NIRISS.GR700XD.1.txt'), unpack=True)
            bandpass = svo.Filter('GR700XD', throughput, n_bins=1, wl_min=mn, wl_max=mx, verbose=False)
            
            # Calculate the LDCs
            ldcs = lf.ldc(None, None, None, model_grid, [ld_profile], bandpass=bandpass, grid_point=grid_point.copy(), mu_min=0.08, verbose=False)
            coeffs = list(zip(*ldcs[ld_profile]['coeffs']))[1::2]
            coeffs = [coeffs[0][0],coeffs[1][0]]
            
            return ('{:.9f}'.format(wavelength), coeffs)
            
        except:
            
            print(wavelength)
            
            return ('_', None)
            
    # Pool the LDC calculations across the whole wavelength range for each order
    for order in [1,2]:
        
        # Get the wavelength limits for this order
        min_wave = np.nanmin(wave_maps[order-1][wave_maps[order-1]>0])
        max_wave = np.nanmax(wave_maps[order-1][wave_maps[order-1]>0])
        
        # Generate list of binned wavelengths
        wavelengths = np.arange(min_wave, max_wave, delta_w)
        
        # Turn off printing
        print('Calculating order {} LDCs at {} wavelengths...'.format(order,len(wavelengths)))
        sys.stdout = open(os.devnull, 'w')
        
        # Pool the LDC calculations across the whole wavelength range
        processes = 8
        start = time.time()
        pool = multiprocessing.pool.ThreadPool(processes)
        
        func = partial(gr700xd_ldc, 
                       delta_w    = delta_w,
                       ld_profile = ld_profile,
                       grid_point = grid_point,
                       model_grid = model_grid)
                       
        # Turn list of coeffs into a dictionary
        order_dict = dict(pool.map(func, wavelengths))
        
        pool.close()
        pool.join()
        
        # Add the dict to the master
        try:
            order_dict.pop('_')
        except:
            pass
        lookup['order{}'.format(order)] = order_dict
        
        # Turn printing back on
        sys.stdout = sys.__stdout__
        print('Order {} LDCs finished: '.format(order), time.time()-start)
        
    if save:
        t, g, m = grid_point['Teff'], grid_point['logg'], grid_point['FeH']
        joblib.dump(lookup, save+'/{}_ldc_lookup_{}_{}_{}.save'.format(ld_profile,t,g,m))
        
    else:
    
        return lookup

def ld_coefficient_map(lookup, subarray='SUBSTRIP256', save=''):
    """
    Generate  map of limb darkening coefficients at every NIRISS pixel for all SOSS orders
    
    Parameters
    ----------
    lookup: str, array-like
        The path to the lookup table of LDCs
    subarray: str
        The subarray to use
    save: bool
        Save the data to file
    
    Example
    -------
    ld_coeffs_lookup = ld_coefficient_lookup(1, 'quadratic', star, model_grid)
    """
    if isinstance(lookup, str):
        
        # Get the lookup table
        ld_profile = os.path.basename(lookup).split('_')[0]
        lookup = joblib.load(lookup)
    
    # Get the wavelength map
    nrows = 256 if subarray=='SUBSTRIP256' else 96 if subarray=='SUBSTRIP96' else 2048
    wave_map = wave_solutions(nrows)
        
    # Make dummy array for LDC map results
    ldfunc = lf.ld_profile(ld_profile)
    ncoeffs = len(inspect.signature(ldfunc).parameters)-1
    ld_coeffs = np.zeros((3, nrows*2048, ncoeffs))
    
    # Calculate the coefficients at each pixel for each order
    for order,wavelengths in enumerate(wave_map[:1]):
        
        # Get a flat list of all wavelengths for this order
        wave_list = wavelengths.flatten()
        lkup = lookup['order{}'.format(order+1)]
        
        # Get the bin size
        delta_w = np.mean(np.diff(sorted(np.array(list(map(float,lkup))))))/2.
        
        # For each bin in the lookup table...
        for bin, coeffs in lkup.items():
            
            try:
                
                # Get all the pixels that fall within the bin
                w = float(bin)
                idx, = np.where(np.logical_and(wave_list>=w-delta_w,wave_list<=w+delta_w))
                
                # Place them in the coefficient map
                ld_coeffs[order][idx] = coeffs
                
            except:
                 
                print(bin)
                
    if save:
        path = lookup_file.replace('lookup','map')
        joblib.dump(ld_coeffs, path)
        
        print('LDC coefficient map saved at',path)
        
    else:
        
        return ld_coeffs
        
def generate_SOSS_psfs(filt):
    """
    Gnerate a cube of the psf at 100 wavelengths from the min to the max wavelength
    
    Parameters
    ----------
    filt: str
        The filter to use, ['CLEAR','F277W']
    """
    # Get the file
    file = pkg_resources.resource_filename('AWESim_SOSS', 'files/SOSS_{}_PSF.fits'.format(filt))
    
    # Get the NIRISS class from webbpsf and set the filter
    ns = webbpsf.NIRISS()
    ns.filter = filt
    ns.pupil_mask = 'GR700XD'
    
    # Get the min and max wavelengths
    wavelengths = wave_solutions(256).flatten()
    wave_min = np.max([ns.SHORT_WAVELENGTH_MIN*1E6,np.min(wavelengths[wavelengths>0])])
    wave_max = np.min([ns.LONG_WAVELENGTH_MAX*1E6,np.max(wavelengths[wavelengths>0])])
    
    # webbpsf.calc_datacube can only handle 100 but that's sufficient
    W = np.linspace(wave_min, wave_max, 100)[::-1]*1E-6
    
    # Calculate the psfs
    print("Generating SOSS psfs. This takes about 8 minutes...")
    start = time.time()
    PSF = ns.calc_datacube(W, oversample=1)[0].data
    print("Finished in",time.time()-start)
    
    # Make the HDUList
    psfhdu = fits.PrimaryHDU(data=PSF)
    wavhdu = fits.ImageHDU(data=W*1E6, name='WAV')
    hdulist = fits.HDUList([psfhdu, wavhdu])
    
    # Write the file
    hdulist.writeto(file, overwrite=True)
    hdulist.close()
    
def SOSS_psf_cube(filt='CLEAR', order=1, generate=False):
    """
    Generate/retrieve a data cube of shape (3, 2048, 76, 76) 
    
    Parameters
    ----------
    filt: str
        The filter to use, ['CLEAR','F277W']
    order: int
        The trace order
    generate: bool
        Generate a new cube
    
    Returns
    -------
    np.ndarray
        An array of the SOSS psf at 2048 wavelengths for each order
    """
    if generate:
        
        # Get the wavelengths
        wavelengths = np.mean(wave_solutions(256), axis=1)
        
        # Get the file
        psf_file = pkg_resources.resource_filename('AWESim_SOSS', 'files/SOSS_{}_PSF.fits'.format(filt))
        
        # Load the SOSS psf cube
        cube = fits.getdata(psf_file).swapaxes(-1,-2)
        wave = fits.getdata(psf_file, ext=1)
        
        # Initilize interpolator
        psfs = interp1d(wave, cube, axis=0, kind=3)
        
        # Run datacube
        for n,order in enumerate(wavelengths):
            
            # Get the file
            file = pkg_resources.resource_filename('AWESim_SOSS', 'files/SOSS_{}_PSF_order{}.fits'.format(filt,n+1))
            
            print('Calculating order {} SOSS psfs for {} filter...'.format(n+1,filt))
            start = time.time()
            
            pool = multiprocessing.Pool(8)
            
            # Set wavelength independent inputs of lightcurve function
            func = partial(get_SOSS_psf, filt=filt, psfs=psfs)
            
            # Generate the psfs at each wavelength
            all_psfs = pool.map(func, order)
            
            # Close the pool
            pool.close()
            pool.join()
            
            print('Finished in {} seconds.'.format(time.time()-start))
            
            # Write to the file
            fits.HDUList([fits.PrimaryHDU(data=np.array(all_psfs))]).writeto(file, overwrite=True)
            print('Data saved to',file)
        
    else:
        
        # Get the file
        file = pkg_resources.resource_filename('AWESim_SOSS', 'files/SOSS_{}_PSF_order{}.fits'.format(filt,order))
        
        return fits.getdata(file)

def get_SOSS_psf(wavelength, filt='CLEAR', psfs=''):
    """
    Retrieve the SOSS psf for the given wavelength
    
    Parameters
    ----------
    wavelength: float
        The wavelength to retrieve [um]
    filt: str
        The filter to use, ['CLEAR','F277W']
    psfs: numpy.interp1d object (optional)
        The interpolator
    
    Returns
    -------
    np.ndarray
        The 2D psf for the input wavelength
    """
    if psfs=='':
        
        # Get the file
        file = pkg_resources.resource_filename('AWESim_SOSS', 'files/SOSS_{}_PSF.fits'.format(filt))
        
        # Load the SOSS psf cube
        cube = fits.getdata(file).swapaxes(-1,-2)
        wave = fits.getdata(file, ext=1)
        
        # Initilize interpolator
        psfs = interp1d(wave, cube, axis=0, kind=3)
        
    # Check the wavelength
    if wavelength<psfs.x[0]:
        wavelength = psfs.x[0]
        
    if wavelength>psfs.x[-1]:
        wavelength = psfs.x[-1]
        
    # Interpolate and scale psf
    psf = psfs(wavelength)
    psf *= 1./np.nansum(psf)
        
    return psf

def psf_lightcurve(wavelength, psf, response, pfd2adu, ld_coeffs, ld_profile, star, planet, time, params, filt, floor=2, plot=False):
    """
    Generate a lightcurve for a given wavelength
    
    Parameters
    ----------
    wavelength: float
        The wavelength value in microns
    response: float
        The spectral response of the detector at the given wavelength
    ld_coeffs: array-like
        A 3D array that assigns limb darkening coefficients to each pixel, i.e. wavelength
    ld_profile: str
        The limb darkening profile to use
    pfd2adu: sequence
        The factor that converts photon flux density to ADU/s
    star: sequence
        The wavelength and flux of the star
    planet: sequence
        The wavelength and Rp/R* of the planet at t=0 
    t: sequence
        The time axis for the TSO
    params: batman.transitmodel.TransitParams
        The transit parameters of the planet
    filt: str
        The filter to apply, ['CLEAR','F277W']
    floor: int
        The noise floor in counts
    plot: bool
        Plot the lightcurve
    verbose: bool
        Print some details
    
    Returns
    -------
    sequence
        A 1D array of the lightcurve with the same length as *t* 
    
    Example
    -------
    from AWESim_SOSS.sim2D import awesim
    import astropy.units as q, os, AWESim_SOSS
    DIR_PATH = os.path.dirname(os.path.realpath(AWESim_SOSS.__file__))
    vega = np.genfromtxt(DIR_PATH+'/files/scaled_spectrum.txt', unpack=True) # A0V with Jmag=9
    w = vega[0]*q.um
    f = (vega[1]*q.W/q.m**2/q.um).to(q.erg/q.s/q.cm**2/q.AA)
    lc = awesim.psf_lightcurve(0.97, 1, 1, 1, '', [w,f], '', np.arange(10), '', 'CLEAR', plot=True)
    """
    if not isinstance(ld_coeffs, list) or not isinstance(ld_coeffs, np.ndarray):
        ld_coeffs  = [ld_coeffs]
        ld_profile = 'linear'
        
    # I = (Stellar Flux)*(LDC)*(Transit Depth)*(Filter Throughput)*(PSF position)
    # Don't use astropy units! It quadruples the computing time!
    
    # Get the energy flux density [erg/s/cm2/A] at the given wavelength [um] at t=t0
    flux0 = np.interp(wavelength, star[0], star[1], left=0, right=0)*psf
    # print('Energy Flux Density [erg/s/cm2/A]:',flux0)
    
    # Convert from energy flux density to photon flux density [photons/s/cm2/A]
    # by multiplying by (lambda/h*c)
    flux0 *= wavelength*503411665111.4543 # [1/erg*um]
    # print('Photon Flux Density [1/s/cm2/A]:',flux0)
    
    # Convert from photon flux density to ADU/s by multiplying by the wavelength 
    # interval [um/pixel] and primary mirror area [cm2], and dividing by the gain [e-/ADU]
    flux0 *= pfd2adu
    # print('Count Rate [ADU/s * 1/e-]:',flux0)
    
    # Expand to shape of time axis
    flux = np.tile(flux0, (len(time),1,1))
    
    # If there is a transiting planet...
    if not isinstance(planet,str):
        
        # Set the wavelength dependent orbital parameters
        params.limb_dark = ld_profile
        params.u = ld_coeffs
        
        # Set the radius at the given wavelength from the transmission spectrum (Rp/R*)**2
        tdepth = np.interp(wavelength, planet[0], planet[1])
        params.rp = np.sqrt(tdepth)
        
        # Generate the light curve for this pixel
        model = batman.TransitModel(params, time) 
        lightcurve = model.light_curve(params)
        
        # Scale the flux with the lightcurve
        flux *= lightcurve
        
    # Apply the filter response
    flux *= response
    
    # Replace very low signal pixels with noise floor
    # flux[flux<floor] += np.random.normal(loc=floor, scale=1, size=len(flux[flux<floor]))
    # flux[flux<floor] += np.repeat(floor, len(flux[flux<floor]))
    
    # Plot
    if plot:
        plt.plot(time, np.nanmean(flux, axis=(1,2)))
        plt.xlabel("Time from central transit")
        plt.ylabel("Flux Density [photons/s/cm2/A]")
        
    return flux

def wave_solutions(subarr, directory=pkg_resources.resource_filename('AWESim_SOSS', '/files/soss_wavelengths_fullframe.fits')):
    """
    Get the wavelength maps for SOSS orders 1, 2, and 3
    This will be obsolete once the apply_wcs step of the JWST pipeline
    is in place.
     
    Parameters
    ==========
    subarr: str
        The subarray to return, accepts '96', '256', or 'full'
    directory: str
        The directory containing the wavelength FITS files
        
    Returns
    =======
    np.ndarray
        An array of the wavelength solutions for orders 1, 2, and 3
    """
    try:
        idx = int(subarr)
    except:
        idx = None
    
    wave = fits.getdata(directory).swapaxes(-2,-1)[:,:idx,::-1]
    
    return wave

def get_frame_times(subarray, ngrps, nints, t0, nresets=1):
    """
    Calculate a time axis for the exposure in the given SOSS subarray
    
    Parameters
    ----------
    subarray: str
        The subarray name, i.e. 'SUBSTRIP256', 'SUBSTRIP96', or 'FULL'
    ngrps: int
        The number of groups per integration
    nints: int
        The number of integrations for the exposure
    t0: float
        The start time of the exposure
    nresets: int
        The number of reset frames per integration
    
    Returns
    -------
    sequence
        The time of each frame
    """
    # Check the subarray
    if subarray not in ['SUBSTRIP256','SUBSTRIP96','FULL']:
        subarray = 'SUBSTRIP256'
        print("I do not understand subarray '{}'. Using 'SUBSTRIP256' instead.".format(subarray))
    
    # Get the appropriate frame time
    ft = FRAME_TIMES[subarray]
    
    # Generate the time axis, removing reset frames
    time_axis = []
    t = t0
    for _ in range(nints):
        times = t+np.arange(nresets+ngrps)*ft
        t = times[-1]+ft
        time_axis.append(times[nresets:])
    
    time_axis = np.concatenate(time_axis)
    
    return time_axis

def trace_polynomials(subarray='SUBSTRIP256', order=4, generate=False):
    """
    Determine the polynomials of the SOSS traces from the IDT's values
    
    Parameters
    ----------
    subarray: str
        The name of the subarray
    order: int
        The order polynomail to fit
    generate: bool
        Generate new coefficients
    
    Returns
    -------
    sequence
        The list of polynomial coefficients for orders 1  and 2
    """
    if generate:
        
        # Get the data
        file = pkg_resources.resource_filename('AWESim_SOSS', 'files/soss_wavelength_trace_table1.txt')
        x1, y1,w1, x2, y2, w2 = np.genfromtxt(file, unpack=True)
        
        # Subarray 96
        if subarray=='SUBSTRIP96':
            y1 -= 10
            y2 -= 10
            
        # Fit the polynomails
        fit1 = np.polyfit(x1, y1, order)
        fit2 = np.polyfit(x2, y2, order)
        
        # Plot the results
        plt.figure(figsize=(13,2))
        plt.plot(x1, y1, c='b', marker='o', ls='none', label='Order 1')
        plt.plot(x2, y2, c='b', marker='o', ls='none', label='Order 2')
        plt.plot(x1, np.polyval(fit1, x1), c='r', label='Order 1 Fit')
        plt.plot(x2, np.polyval(fit2, x2), c='r', label='Order 2 Fit')
        plt.xlim(0,2048)
        if subarray=='SUBSTRIP96':
            plt.ylim(0,96)
        else:
            plt.ylim(0,256)
        plt.legend(loc=0)
        
        return fit1, fit2
        
    else:
        
        if subarray=='SUBSTRIP96':
            coeffs = [[1.71164994e-11, -4.72119272e-08, 5.10276801e-05, -5.91535309e-02, 7.30680347e+01], [2.35792131e-13, 2.42999478e-08, 1.03641247e-05, -3.63088657e-02, 8.96766537e+01]]
        else:
            coeffs = [[1.71164994e-11, -4.72119272e-08, 5.10276801e-05, -5.91535309e-02, 8.30680347e+01], [2.35792131e-13, 2.42999478e-08, 1.03641247e-05, -3.63088657e-02, 9.96766537e+01]]

        return coeffs

class TSO(object):
    """
    Generate NIRISS SOSS time series observations
    """
    def __init__(self, ngrps, nints, star, snr=700, subarray='SUBSTRIP256', t0=0, target=''):
        """
        Iterate through all pixels and generate a light curve if it is inside the trace
        
        Parameters
        ----------
        ngrps: int
            The number of groups per integration
        nints: int
            The number of integrations for the exposure
        star: sequence
            The wavelength and flux of the star
        snr: float
            The signal-to-noise
        subarray: str
            The subarray name, i.e. 'SUBSTRIP256', 'SUBSTRIP96', or 'FULL'
        t0: float
            The start time of the exposure
        target: str (optional)
            The name of the target
                        
        Example
        -------
        # Imports
        from AWESim_SOSS.sim2D import awesim
        import astropy.units as q, astropy.constants as ac, os, AWESim_SOSS, batman
        DIR_PATH = os.path.dirname(os.path.realpath(AWESim_SOSS.__file__))
        star = np.genfromtxt(DIR_PATH+'/files/scaled_spectrum.txt', unpack=True)
        star1D = [star[0]*q.um, (star[1]*q.W/q.m**2/q.um).to(q.erg/q.s/q.cm**2/q.AA)]
        
        # Initialize simulation
        tso = awesim.TSO(ngrps=5, nints=2, star=star1D)
        """
        # Set instance attributes for the exposure
        self.subarray = subarray
        self.nrows = 256 if '256' in subarray else 96 if '96' in subarray else 2048
        self.ncols = 2048
        self.ngrps = ngrps
        self.nints = nints
        self.nresets = 1
        self.frame_time = FRAME_TIMES[subarray]
        self.time = get_frame_times(subarray, ngrps, nints, t0, self.nresets)
        self.nframes = len(self.time)
        self.target = target or 'Simulated Target'
        self.obs_date = '2016-01-04'
        self.obs_time = '23:37:52.226'
        self.filter = 'CLEAR'
        self.header = ''
        self.snr = snr
        
        # Set instance attributes for the target
        self.star = star
        self.wave = wave_solutions(str(self.nrows))
        self.planet = ''
        self.params = ''
        self.ld_profile = ''
        self.ld_coeffs = np.zeros((2, self.nrows*self.ncols, 2))
        
        # Calculate a map for each order that converts photon flux density to ADU/s
        self.gain = 1.61 # [e-/ADU]
        self.primary_mirror = 253260 # [cm2]
        self.avg_wave = np.mean(self.wave, axis=1)
        self.pfd2adu = np.ones((3,self.ncols))
        for n,aw in enumerate(self.avg_wave):
            coeffs = np.polyfit(aw[:-1], np.diff(aw), 1)
            wave_int = (np.polyval(coeffs, self.avg_wave[n])*q.um).to(q.AA)
            self.pfd2adu[n] = (wave_int*self.primary_mirror*q.cm**2/self.gain).to(q.cm**2*q.AA).value.flatten()
            
        # Add the orbital parameters as attributes
        for p in [i for i in dir(self.params) if not i.startswith('_')]:
            setattr(self, p, getattr(self.params, p))
            
        # Create the empty exposure
        self.dims = (self.nframes, self.nrows, self.ncols)
        self.tso = np.zeros(self.dims)
        self.tso_ideal = np.zeros(self.dims)
        self.tso_order1_ideal = np.zeros(self.dims)
        self.tso_order2_ideal = np.zeros(self.dims)
    
    def run_simulation(self, filt='CLEAR', planet='', params='', ld_profile='quadratic', ld_coeffs='', verbose=True):
        """
        Generate the simulated 2D data given the initialized TSO object
        
        Parameters
        ----------
        filt: str
            The element from the filter wheel to use, i.e. 'CLEAR' or 'F277W'
        planet: sequence (optional)
            The wavelength and Rp/R* of the planet at t=0 
        params: batman.transitmodel.TransitParams (optional)
            The transit parameters of the planet
        ld_profile: str (optional)
            The limb darkening profile to use
        ld_coeffs: array-like (optional)
            A 3D array that assigns limb darkening coefficients to each pixel, i.e. wavelength
        
        Example
        -------
        # Run simulation of star only
        tso.run_simulation()
        
        # Simulate star with transiting exoplanet by including transmission spectrum and orbital params
        planet1D = np.genfromtxt(DIR_PATH+'/files/WASP107b_pandexo_input_spectrum.dat', unpack=True)
        params = batman.TransitParams()
        params.t0 = 0.                                # time of inferior conjunction
        params.per = 5.7214742                        # orbital period (days)
        params.a = 0.0558*q.AU.to(ac.R_sun)*0.66      # semi-major axis (in units of stellar radii)
        params.inc = 89.8                             # orbital inclination (in degrees)
        params.ecc = 0.                               # eccentricity
        params.w = 90.                                # longitude of periastron (in degrees)
        params.teff = 3500                            # effective temperature of the host star
        params.logg = 5                               # log surface gravity of the host star
        params.feh = 0                                # metallicity of the host star
        tso.run_simulation(planet=planet1D, params=params)
        """
        if verbose:
            begin = time.time()
        
        # Clear previous results
        self.tso = np.zeros(self.dims)
        self.tso_ideal = np.zeros(self.dims)
        
        # Check if it's F277W to speed up calculation
        if 'F277W' in filt.upper():
            orders = [1]
            self.filter = 'F277W'
        else:
            orders = [1,2]
            
        # If there is a planet transmission spectrum but no LDCs, generate them
        if planet!='':
            
            # Store planet details
            self.planet = planet
            self.params = params
            self.ld_coeffs = ld_coeffs or np.zeros((2, self.nrows*self.ncols, 2))
            self.ld_profile = ld_profile or 'quadratic'
            
            if verbose:
                print('Calculating limb darkening coefficients...')
                start = time.time()
            
            # Generate the lookup table
            stellar_params = [getattr(params, p) for p in ['teff','logg','feh']]
            lookup = ldc_lookup(self.ld_profile, stellar_params)
            
            # Generate the coefficient map
            self.ld_coeffs = ld_coefficient_map(lookup, subarray=self.subarray)
            
            if verbose:
                print('Finished limb darkening coefficients:',start-time.time())
            
        # Generate simulation for each order
        for order in orders:
            
            # Get the wavelength map
            wave = self.avg_wave[order-1]
            
            # Get the psf cube
            cube = SOSS_psf_cube(filt=filt, order=order, generate=False)
            
            # Get limb darkening map
            ld_coeffs = self.ld_coeffs[order-1]
            
            # Get relative spectral response map
            throughput = np.genfromtxt(pkg_resources.resource_filename('AWESim_SOSS', 'files/gr700xd_{}_order{}.dat'.format(self.filter,order)), unpack=True)
            response = np.interp(wave, throughput[0], throughput[-1], left=0, right=0)
            
            # Get the wavelength interval per pixel map
            pfd2adu = self.pfd2adu[order-1]
            
            if isinstance(ld_coeffs[0], float):
                ld_coeffs = np.transpose([[ld_coeffs[0], ld_coeffs[1]]] * wave.size)
                
            # Make sure the ld_coeffs are lists
            ld_coeffs = list(map(list, ld_coeffs))
            
            # Caluclate the transform for the desired polynomial
            tform = transform_from_polynomial(self.nrows, self.ncols, trace_polynomials(self.subarray, generate=False)[order-1])
            
            # Run multiprocessing to generate lightcurves
            if verbose:
                print('Calculating order {} light curves...'.format(order))
                start = time.time()
            pool = multiprocessing.Pool(8)
            
            # Set wavelength independent inputs of lightcurve function
            func = partial(psf_lightcurve, ld_profile=self.ld_profile, star=self.star, planet=self.planet, time=self.time, params=self.params, filt=self.filter)
            
            # Generate the lightcurves at each wavelength
            psfs = np.asarray(pool.starmap(func, list(zip(wave, cube, response, pfd2adu, ld_coeffs))))
            psfs = psfs.swapaxes(0,1)
            psfs = psfs.swapaxes(2,3)
            
            # Close the pool
            pool.close()
            pool.join()
            
            # Generate TSO frames with linear traces
            if verbose:
                print('Lightcurves finished:',time.time()-start)
                print('Constructing order {} linear traces...'.format(order))
                start = time.time()
            frames = make_linear_SOSS_trace(psfs)
            
            # Run multiprocessing to construct trace
            if verbose:
                print('Order {} linear traces finished:'.format(order),time.time()-start)
                print('Constructing order {} warped traces...'.format(order))
                start = time.time()
            pool = multiprocessing.Pool(8)

            # Load the warp function with the precomputed transform
            func = partial(warp, inverse_map=tform.inverse)#, output_shape=(self.nrows, self.ncols))

            # Generate the warped trace at each frame
            tso_order = np.asarray(pool.map(func, frames))

            # Close the pool
            pool.close()
            pool.join()
            if verbose:
                print('Order {} warped traces finished:'.format(order), time.time()-start)
                
            # Add it to the individual order
            setattr(self, 'tso_order{}_ideal'.format(order), tso_order)
            
        # Add to the master TSO
        self.tso = np.sum([getattr(self, 'tso_order{}_ideal'.format(order)) for order in orders], axis=0)
        
        # Add noise to the observations using Kevin Volk's dark ramp simulator
        self.tso_ideal = self.tso.copy()
        
        # Add noise and ramps
        # self.add_noise(verbose=verbose)
        
        if verbose:
            print('\nTotal time:',time.time()-begin)
    
    def add_noise(self, zodi_scale=1., offset=500, verbose=True):
        """
        Generate ramp and background noise
        
        Parameters
        ----------
        zodi_scale: float
            The scale factor of the zodiacal background
        offset: int
            The dark current offset
        """
        if verbose:
            print('Adding noise to TSO...')
            start = time.time()
        
        # Get the separated orders
        orders = np.asarray([self.tso_order1_ideal,self.tso_order2_ideal])
        
        # Load all the reference files
        photon_yield = fits.getdata(pkg_resources.resource_filename('AWESim_SOSS', 'files/photon_yield_dms.fits'))
        pca0_file = pkg_resources.resource_filename('AWESim_SOSS', 'files/niriss_pca0.fits')
        zodi = fits.getdata(pkg_resources.resource_filename('AWESim_SOSS', 'files/soss_zodiacal_background_scaled.fits'))
        nonlinearity = fits.getdata(pkg_resources.resource_filename('AWESim_SOSS', 'files/substrip256_forward_coefficients_dms.fits'))
        pedestal = fits.getdata(pkg_resources.resource_filename('AWESim_SOSS', 'files/substrip256pedestaldms.fits'))
        darksignal = fits.getdata(pkg_resources.resource_filename('AWESim_SOSS', 'files/substrip256signaldms.fits'))*self.gain
        
        # Generate the photon yield factor values
        pyf = gd.make_photon_yield(photon_yield, np.mean(orders, axis=1))
        
        # Remove negatives from the dark ramp
        darksignal[np.where(darksignal < 0.)] = 0.
        
        # Make the exposure
        RAMP = gd.make_exposure(1, self.ngrps, darksignal, self.gain, pca0_file=pca0_file, offset=offset)
        
        # Iterate over integrations
        for n in range(self.nints):
            
            # Add in the SOSS signal
            ramp = gd.add_signal(self.tso_ideal[self.ngrps*n:self.ngrps*n+self.ngrps], RAMP.copy(), pyf, self.frame_time, self.gain, zodi, zodi_scale, photon_yield=False)
            
            # Apply the non-linearity function
            ramp = gd.non_linearity(ramp, nonlinearity, offset=offset)
            
            # Add the pedestal to each frame in the integration
            ramp = gd.add_pedestal(ramp, pedestal, offset=offset)
            
            # Update the TSO with one containing noise
            self.tso[self.ngrps*n:self.ngrps*n+self.ngrps] = ramp
            
        if verbose:
            print('Noise model finished:', time.time()-start)
        
    def plot_frame(self, frame='', scale='linear', order='', noise=True, cmap=cm.jet):
        """
        Plot a TSO frame
        
        Parameters
        ----------
        frame: int
            The frame number to plot
        scale: str
            Plot in linear or log scale
        order: int (optional)
            The order to isolate
        noise: bool
            Plot with the noise model
        cmap: str
            The color map to use
        """
        if order:
            tso = getattr(self, 'tso_order{}_ideal'.format(order))
        else:
            if noise:
                tso = self.tso
            else:
                tso = self.tso_ideal
        
        vmax = int(np.nanmax(tso))
        
        plt.figure(figsize=(13,2))
        if scale=='log':
            plt.imshow(tso[frame or self.nframes//2].data, origin='lower', interpolation='none', norm=matplotlib.colors.LogNorm(), vmin=1, vmax=vmax, cmap=cmap)
        else:
            plt.imshow(tso[frame or self.nframes//2].data, origin='lower', interpolation='none', vmin=1, vmax=vmax, cmap=cmap)
        plt.colorbar()
        plt.title('Injected Spectrum')
    
    def plot_snr(self, frame='', cmap=cm.jet):
        """
        Plot the SNR of a TSO frame
        
        Parameters
        ----------
        frame: int
            The frame number to plot
        cmap: matplotlib.cm.colormap
            The color map to use
        """
        # Get the SNR
        snr  = np.sqrt(self.tso[frame or self.nframes//2].data)
        vmax = int(np.nanmax(snr))
        
        # Plot it
        plt.figure(figsize=(13,2))
        plt.imshow(snr, origin='lower', interpolation='none', vmin=1, vmax=vmax, cmap=cmap)
        plt.colorbar()
        plt.title('SNR over Spectrum')
        
    def plot_saturation(self, frame='', saturation=80.0, cmap=cm.jet):
        """
        Plot the saturation of a TSO frame
        
        Parameters
        ----------
        frame: int
            The frame number to plot
        saturation: float
            Percentage of full well that defines saturation
        cmap: matplotlib.cm.colormap
            The color map to use
        """
        # The full well of the detector pixels
        fullWell = 65536.0
        
        # Get saturated pixels
        saturated = np.array(self.tso[frame or self.nframes//2].data) > (saturation/100.0) * fullWell
        
        # Plot it
        plt.figure(figsize=(13,2))
        plt.imshow(saturated, origin='lower', interpolation='none', cmap=cmap)
        plt.colorbar()
        plt.title('{} Saturated Pixels'.format(len(saturated[saturated>fullWell])))
    
    def plot_slice(self, col, trace='tso', frame=0, order='', **kwargs):
        """
        Plot a column of a frame to see the PSF in the cross dispersion direction
        
        Parameters
        ----------
        col: int, sequence
            The column index(es) to plot a light curve for
        trace: str
            The attribute name to plot
        frame: int
            The frame number to plot
        """
        if order:
            tso = getattr(self, 'tso_order{}_ideal'.format(order))
        else:
            tso = self.tso
            
        f = tso[frame].T
        
        if isinstance(col, int):
            col = [col]
            
        for c in col:
            plt.plot(f[c], label='Column {}'.format(c), **kwargs)
            
        plt.xlim(0,256)
        
        plt.legend(loc=0, frameon=False)
        
    def plot_ramp(self):
        """
        Plot the total flux on each frame to display the ramp
        """
        plt.figure()
        plt.plot(np.sum(self.tso, axis=(1,2)), ls='none', marker='o')
        plt.xlabel('Group')
        plt.ylabel('Count Rate [ADU/s]')
        plt.grid()
        
    def plot_lightcurve(self, col):
        """
        Plot a lightcurve for each column index given
        
        Parameters
        ----------
        col: int, float, sequence
            The integer column index(es) or float wavelength(s) in microns 
            to plot as a light curve
        """
        # Get the scaled flux in each column
        f = np.nansum(self.tso, axis=1)
        f = f/np.nanmax(f, axis=1)[:,None]
        
        # Make it into an array
        if isinstance(col, (int,float)):
            col = [col]
            
        for c in col:
            
            # If it is an index
            if isinstance(c, int):
                lc = f[:,c]
                label = 'Col {}'.format(c)
                
            # Or assumed to be a wavelength in microns
            elif isinstance(c, float):
                W = np.mean(self.wave[0], axis=0)
                lc = [np.interp(c, W, F) for F in f]
                label = '{} um'.format(c)
                
            else:
                print('Please enter an index, astropy quantity, or array thereof.')
                return
            
            plt.plot(self.time, lc, label=label, marker='.', ls='None')
            
        plt.legend(loc=0, frameon=False)
        
    def plot_spectrum(self, frame=0, order=''):
        """
        Parameters
        ----------
        frame: int
            The frame number to plot
        """
        if order:
            tso = getattr(self, 'tso_order{}_ideal'.format(order))
        else:
            tso = self.tso
        
        # Get extracted spectrum (Column sum for now)
        wave = np.mean(self.wave[0], axis=0)
        flux = np.sum(tso[frame].data, axis=0)
        
        # Deconvolve with the grism
        throughput = np.genfromtxt(pkg_resources.resource_filename('AWESim_SOSS', 'files/gr700xd_{}_order{}.dat'.format(self.filter,order or 1)), unpack=True)
        flux *= np.interp(wave, throughput[0], throughput[-1], left=0, right=0)
        
        # Convert from ADU/s to photon flux density
        wave_int = np.diff(wave)*q.um.to(q.AA)
        flux /= (np.array(list(wave_int)+[wave_int[-1]])*self.primary_mirror*q.cm**2/self.gain).value.flatten()
        
        # Convert from photon flux density to energy flux density
        flux /= wave*503411665111.4543 # [1/erg*um]
        
        # Plot it along with input spectrum
        plt.figure(figsize=(13,5))
        plt.loglog(wave, flux, label='Extracted')
        plt.loglog(*self.star, label='Injected')
        plt.xlim(wave[0]*0.95,wave[-1]*1.05)
        plt.legend()
    
    def save(self, filename='dummy.save'):
        """
        Save the TSO data to file
        
        Parameters
        ----------
        filename: str
            The path of the save file
        """
        print('Saving TSO class dict to {}'.format(filename))
        joblib.dump(self.__dict__, filename)
    
    def load(self, filename):
        """
        Load a previously calculated TSO
        
        Paramaters
        ----------
        filename: str
            The path of the save file
        
        Returns
        -------
        awesim.TSO()
            A TSO class dict
        """
        print('Loading TSO class dict to {}'.format(filename))
        load_dict = joblib.load(filename)
        # for p in [i for i in dir(load_dict)]:
        #     setattr(self, p, getattr(params, p))
        for key in load_dict.keys():
            exec("self." + key + " = load_dict['" + key + "']")
    
    def to_fits(self, outfile):
        """
        Save the data to a JWST pipeline ingestible FITS file
        
        Parameters
        ----------
        outfile: str
            The path of the output file
        """
        # Make the cards
        cards = [('DATE', datetime.datetime.now().strftime("%Y-%m-%dT%H:%M:%S"), 'Date file created yyyy-mm-ddThh:mm:ss, UTC'),
                ('FILENAME', outfile, 'Name of the file'),
                ('DATAMODL', 'RampModel', 'Type of data model'),
                ('ORIGIN', 'STScI', 'Institution responsible for creating FITS file'),
                ('TIMESYS', 'UTC', 'principal time system for time-related keywords'),
                ('FILETYPE', 'uncalibrated', 'Type of data in the file'),
                ('SDP_VER', '2016_1', 'data processing software version number'),
                ('PRD_VER', 'PRDDEVSOC-D-012', 'S&OC PRD version number used in data processing'),
                ('TELESCOP', 'JWST', 'Telescope used to acquire data'),
                ('RADESYS', 'ICRS', 'Name of the coordinate reference frame'),
                ('', '', ''),
                ('COMMENT', '/ Program information', ''),
                ('TITLE', 'UNKNOWN', 'Proposal title'),
                ('PI_NAME', 'N/A', 'Principal investigator name'),
                ('CATEGORY', 'UNKNOWN', 'Program category'),
                ('SUBCAT', '', 'Program sub-category'),
                ('SCICAT', '', 'Science category assigned during TAC process'),
                ('CONT_ID', 0, 'Continuation of previous program'),
                ('', '', ''),
                ('COMMENT', '/ Observation identifiers', ''),
                ('DATE-OBS', self.obs_date, 'UT date at start of exposure'),
                ('TIME-OBS', self.obs_time, 'UT time at the start of exposure'),
                ('OBS_ID', 'V87600007001P0000000002102', 'Programmatic observation identifier'),
                ('VISIT_ID', '87600007001', 'Visit identifier'),
                ('PROGRAM', '87600', 'Program number'),
                ('OBSERVTN', '001', 'Observation number'),
                ('VISIT', '001', 'Visit number'),
                ('VISITGRP', '02', 'Visit group identifier'),
                ('SEQ_ID', '1', 'Parallel sequence identifier'),
                ('ACT_ID', '02', 'Activity identifier'),
                ('EXPOSURE', '1', 'Exposure request number'),
                ('', '', ''),
                ('COMMENT', '/ Visit information', ''),
                ('TEMPLATE', 'NIRISS SOSS', 'Proposal instruction template used'),
                ('OBSLABEL', 'Observation label', 'Proposer label for the observation'),
                ('VISITYPE', '', 'Visit type'),
                ('VSTSTART', self.obs_date, 'UTC visit start time'),
                ('WFSVISIT', '', 'Wavefront sensing and control visit indicator'),
                ('VISITSTA', 'SUCCESSFUL', 'Status of a visit'),
                ('NEXPOSUR', 1, 'Total number of planned exposures in visit'),
                ('INTARGET', False, 'At least one exposure in visit is internal'),
                ('TARGOOPP', False, 'Visit scheduled as target of opportunity'),
                ('', '', ''),
                ('COMMENT', '/ Target information', ''),
                ('TARGPROP', '', "Proposer's name for the target"),
                ('TARGNAME', self.target, 'Standard astronomical catalog name for tar'),
                ('TARGTYPE', 'FIXED', 'Type of target (fixed, moving, generic)'),
                ('TARG_RA', 175.5546225, 'Target RA at mid time of exposure'),
                ('TARG_DEC', 26.7065694, 'Target Dec at mid time of exposure'),
                ('TARGURA', 0.01, 'Target RA uncertainty'),
                ('TARGUDEC', 0.01, 'Target Dec uncertainty'),
                ('PROP_RA', 175.5546225, 'Proposer specified RA for the target'),
                ('PROP_DEC', 26.7065694, 'Proposer specified Dec for the target'),
                ('PROPEPOC', '2000-01-01 00:00:00', 'Proposer specified epoch for RA and Dec'),
                ('', '', ''),
                ('COMMENT', '/ Exposure parameters', ''),
                ('INSTRUME', 'NIRISS', 'Identifier for niriss used to acquire data'),
                ('DETECTOR', 'NIS', 'ASCII Mnemonic corresponding to the SCA_ID'),
                ('LAMP', 'NULL', 'Internal lamp state'),
                ('FILTER', self.filter, 'Name of the filter element used'),
                ('PUPIL', 'GR700XD', 'Name of the pupil element used'),
                ('FOCUSPOS', 0.0, 'Focus position'),
                ('', '', ''),
                ('COMMENT', '/ Exposure information', ''),
                ('PNTG_SEQ', 2, 'Pointing sequence number'),
                ('EXPCOUNT', 0, 'Running count of exposures in visit'),
                ('EXP_TYPE', 'NIS_SOSS', 'Type of data in the exposure'),
                ('', '', ''),
                ('COMMENT', '/ Exposure times', ''),
                ('EXPSTART', self.time[0], 'UTC exposure start time'),
                ('EXPMID', self.time[len(self.time)//2], 'UTC exposure mid time'),
                ('EXPEND', self.time[-1], 'UTC exposure end time'),
                ('READPATT', 'NISRAPID', 'Readout pattern'),
                ('NINTS', self.nints, 'Number of integrations in exposure'),
                ('NGROUPS', self.ngrps, 'Number of groups in integration'),
                ('NFRAMES', self.nframes, 'Number of frames per group'),
                ('GROUPGAP', 0, 'Number of frames dropped between groups'),
                ('NSAMPLES', 1, 'Number of A/D samples per pixel'),
                ('TSAMPLE', 10.0, 'Time between samples (microsec)'),
                ('TFRAME', FRAME_TIMES[self.subarray], 'Time in seconds between frames'),
                ('TGROUP', FRAME_TIMES[self.subarray], 'Delta time between groups (s)'),
                ('EFFINTTM', 15.8826, 'Effective integration time (sec)'),
                ('EFFEXPTM', 15.8826, 'Effective exposure time (sec)'),
                ('CHRGTIME', 0.0, 'Charge accumulation time per integration (sec)'),
                ('DURATION', self.time[-1]-self.time[0], 'Total duration of exposure (sec)'),
                ('NRSTSTRT', self.nresets, 'Number of resets at start of exposure'),
                ('NRESETS', self.nresets, 'Number of resets between integrations'),
                ('FWCPOS', float(75.02400207519531), ''),
                ('PWCPOS', float(245.6344451904297), ''),
                ('ZEROFRAM', False, 'Zero frame was downlinkws separately'),
                ('DATAPROB', False, 'Science telemetry indicated a problem'),
                ('SCA_NUM', 496, 'Sensor Chip Assembly number'),
                ('DATAMODE', 91, 'post-processing method used in FPAP'),
                ('COMPRSSD', False, 'data compressed on-board (T/F)'),
                ('SUBARRAY', True, 'Subarray pattern name'),
                # ('SUBARRAY', self.subarray, 'Subarray pattern name'),
                ('SUBSTRT1', 1, 'Starting pixel in axis 1 direction'),
                ('SUBSTRT2', 1793, 'Starting pixel in axis 2 direction'),
                ('SUBSIZE1', self.ncols, 'Number of pixels in axis 1 direction'),
                ('SUBSIZE2', self.nrows, 'Number of pixels in axis 2 direction'),
                ('FASTAXIS', -2, 'Fast readout axis direction'),
                ('SLOWAXIS', -1, 'Slow readout axis direction'),
                ('COORDSYS', '', 'Ephemeris coordinate system'),
                ('EPH_TIME', 57403, 'UTC time from ephemeris start time (sec)'),
                ('JWST_X', 1462376.39634336, 'X spatial coordinate of JWST (km)'),
                ('JWST_Y', -178969.457007469, 'Y spatial coordinate of JWST (km)'),
                ('JWST_Z', -44183.7683640854, 'Z spatial coordinate of JWST (km)'),
                ('JWST_DX', 0.147851665036734, 'X component of JWST velocity (km/sec)'),
                ('JWST_DY', 0.352194454527743, 'Y component of JWST velocity (km/sec)'),
                ('JWST_DZ', 0.032553742839182, 'Z component of JWST velocity (km/sec)'),
                ('APERNAME', 'NIS-CEN', 'PRD science aperture used'),
                ('PA_APER', -290.1, 'Position angle of aperture used (deg)'),
                ('SCA_APER', -697.500000000082, 'SCA for intended target'),
                ('DVA_RA', 0.0, 'Velocity aberration correction RA offset (rad)'),
                ('DVA_DEC', 0.0, 'Velocity aberration correction Dec offset (rad)'),
                ('VA_SCALE', 0.0, 'Velocity aberration scale factor'),
                ('BARTDELT', 0.0, 'Barycentric time correction'),
                ('BSTRTIME', 0.0, 'Barycentric exposure start time'),
                ('BENDTIME', 0.0, 'Barycentric exposure end time'),
                ('BMIDTIME', 0.0, 'Barycentric exposure mid time'),
                ('HELIDELT', 0.0, 'Heliocentric time correction'),
                ('HSTRTIME', 0.0, 'Heliocentric exposure start time'),
                ('HENDTIME', 0.0, 'Heliocentric exposure end time'),
                ('HMIDTIME', 0.0, 'Heliocentric exposure mid time'),
                ('WCSAXES', 2, 'Number of WCS axes'),
                ('CRPIX1', 1955.0, 'Axis 1 coordinate of the reference pixel in the'),
                ('CRPIX2', 1199.0, 'Axis 2 coordinate of the reference pixel in the'),
                ('CRVAL1', 175.5546225, 'First axis value at the reference pixel (RA in'),
                ('CRVAL2', 26.7065694, 'Second axis value at the reference pixel (RA in'),
                ('CTYPE1', 'RA---TAN', 'First axis coordinate type'),
                ('CTYPE2', 'DEC--TAN', 'Second axis coordinate type'),
                ('CUNIT1', 'deg', 'units for first axis'),
                ('CUNIT2', 'deg', 'units for second axis'),
                ('CDELT1', 0.065398, 'first axis increment per pixel, increasing east'),
                ('CDELT2', 0.065893, 'Second axis increment per pixel, increasing nor'),
                ('PC1_1', -0.5446390350150271, 'linear transformation matrix element cos(theta)'),
                ('PC1_2', 0.8386705679454239, 'linear transformation matrix element -sin(theta'),
                ('PC2_1', 0.8386705679454239, 'linear transformation matrix element sin(theta)'),
                ('PC2_2', -0.5446390350150271, 'linear transformation matrix element cos(theta)'),
                ('S_REGION', '', 'spatial extent of the observation, footprint'),
                ('GS_ORDER', 0, 'index of guide star within listed of selected g'),
                ('GSSTRTTM', '1999-01-01 00:00:00', 'UTC time when guide star activity started'),
                ('GSENDTIM', '1999-01-01 00:00:00', 'UTC time when guide star activity completed'),
                ('GDSTARID', '', 'guide star identifier'),
                ('GS_RA', 0.0, 'guide star right ascension'),
                ('GS_DEC', 0.0, 'guide star declination'),
                ('GS_URA', 0.0, 'guide star right ascension uncertainty'),
                ('GS_UDEC', 0.0, 'guide star declination uncertainty'),
                ('GS_MAG', 0.0, 'guide star magnitude in FGS detector'),
                ('GS_UMAG', 0.0, 'guide star magnitude uncertainty'),
                ('PCS_MODE', 'COARSE', 'Pointing Control System mode'),
                ('GSCENTX', 0.0, 'guide star centroid x postion in the FGS ideal'),
                ('GSCENTY', 0.0, 'guide star centroid x postion in the FGS ideal'),
                ('JITTERMS', 0.0, 'RMS jitter over the exposure (arcsec).'),
                ('VISITEND', '2017-03-02 15:58:45.36', 'Observatory UTC time when the visit st'),
                ('WFSCFLAG', '', 'Wavefront sensing and control visit indicator'),
                ('BSCALE', 1, ''),
                ('BZERO', 32768, ''),
                ('NCOLS', float(self.nrows-1), ''),
                ('NROWS', float(self.ncols-1), '')]
        
        # Make the header
        prihdr = fits.Header()
        for card in cards:
            prihdr.append(card, end=True)
            
        # Store the header in the object too
        self.header = prihdr
        
        # Put data into detector coordinates
        data = np.swapaxes(self.tso, 1, 2)[:,:,::-1]
        
        # Make the HDUList
        prihdu = fits.PrimaryHDU(data=data, header=prihdr)
        
        # Write the file
        prihdu.writeto(outfile, overwrite=True)
        
        print('File saved as',outfile)
        